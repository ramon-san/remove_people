{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Examples\n",
    "\n",
    "The following code explores the result of over-the-counter models on the cloud. Results from the local semantic segmentation are comparable to these models and give more flexibility when cropping. These models where not used in the final implementation because they just provide bounding voices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "image_name = 'example_1.jpg'\n",
    "\n",
    "# Add known path to the image.\n",
    "image_path = f\"images/original/{image_name}\"\n",
    "# Clean name of image without the extension.\n",
    "clean_image_name = image_name.split('.')[0]\n",
    "\n",
    "with open(image_path, 'rb') as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "\n",
    "# Normalize AWS Rekognition response\n",
    "def normalize_aws(aws_objects):\n",
    "    normalized_aws = []\n",
    "    for obj in aws_objects:\n",
    "        for instance in obj.get('Instances', []):\n",
    "            normalized_obj = {\n",
    "                'name': obj['Name'],\n",
    "                'bounding_poly': {\n",
    "                    'normalized_vertices': [\n",
    "                        {'x': instance['BoundingBox']['Left'], 'y': instance['BoundingBox']['Top']},\n",
    "                        {'x': instance['BoundingBox']['Left'] + instance['BoundingBox']['Width'], 'y': instance['BoundingBox']['Top']},\n",
    "                        {'x': instance['BoundingBox']['Left'] + instance['BoundingBox']['Width'], 'y': instance['BoundingBox']['Top'] + instance['BoundingBox']['Height']},\n",
    "                        {'x': instance['BoundingBox']['Left'], 'y': instance['BoundingBox']['Top'] + instance['BoundingBox']['Height']}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            normalized_aws.append(normalized_obj)\n",
    "    return normalized_aws\n",
    "\n",
    "# Normalize Google Vision response\n",
    "def normalize_google(google_objects):\n",
    "    normalized_google = []\n",
    "    for obj in google_objects:\n",
    "        vertices = obj.bounding_poly.normalized_vertices\n",
    "        normalized_obj = {\n",
    "            'name': obj.name,\n",
    "            'bounding_poly': {\n",
    "                'normalized_vertices': [\n",
    "                    {'x': vertices[0].x, 'y': vertices[0].y},\n",
    "                    {'x': vertices[1].x, 'y': vertices[1].y},\n",
    "                    {'x': vertices[2].x, 'y': vertices[2].y},\n",
    "                    {'x': vertices[3].x, 'y': vertices[3].y}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        normalized_google.append(normalized_obj)\n",
    "    return normalized_google\n",
    "\n",
    "# Draw bounding boxes with the normalized objects\n",
    "def draw_bounding_boxes(image_path, objects, title):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Add title to the image\n",
    "    title_text = title\n",
    "    title_text_size = draw.textbbox((10, 10), title_text)\n",
    "    title_position = (10, 10)\n",
    "    draw.rectangle([title_position, (title_text_size[2] + 10, title_text_size[3] + 10)], fill='red')\n",
    "    draw.text(title_position, title_text, fill='white')\n",
    "\n",
    "    for obj in objects:\n",
    "        # Add object bounding boxes to the image\n",
    "        box = [(vertex['x'] * image.width, vertex['y'] * image.height) for vertex in obj['bounding_poly']['normalized_vertices']]\n",
    "        draw.line(box + [box[0]], width=3, fill='red')\n",
    "        text = obj['name']\n",
    "        text_bbox = draw.textbbox((box[0][0], box[0][1]), text)\n",
    "        text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "        text_background = [(box[0][0], box[0][1] - text_height), (box[0][0] + text_width, box[0][1])]\n",
    "        draw.rectangle(text_background, fill='red')\n",
    "        draw.text((box[0][0], box[0][1] - text_height), text, fill='white')\n",
    "\n",
    "    save_path = f'images/{title.lower()}/{os.path.basename(image_path)}'\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    image.save(save_path)\n",
    "    # Open the file you just saved.\n",
    "    os.system(f'open {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekognition AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the boto3 client\n",
    "rekognition_client = boto3.client('rekognition')\n",
    "\n",
    "def detect_objects():\n",
    "    response = rekognition_client.detect_labels(\n",
    "        Image={'Bytes': image_bytes},\n",
    "        MaxLabels=40,\n",
    "        MinConfidence=60\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "aws_objects = detect_objects()['Labels']\n",
    "# Make the output uniform to avoid having two drawing functions.\n",
    "normalized_aws_objects = normalize_aws(aws_objects)\n",
    "\n",
    "draw_bounding_boxes(image_path, normalized_aws_objects, 'AWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Vision Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "# Initialize the Vision client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "def detect_objects():    \n",
    "    image = vision.Image(content=image_bytes)\n",
    "    response = client.object_localization(image=image)\n",
    "    objects = response.localized_object_annotations\n",
    "\n",
    "    return objects\n",
    "\n",
    "google_objects = detect_objects()\n",
    "# Make the output uniform to avoid having two drawing functions.\n",
    "normalized_google_objects = normalize_google(google_objects)\n",
    "\n",
    "draw_bounding_boxes(image_path, normalized_google_objects, 'Google')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "removepeople",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
